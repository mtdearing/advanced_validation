{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import math\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in data set\n",
    "data = pd.read_csv(\"breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id number</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>uniformity_of_cell_size</th>\n",
       "      <th>uniformity_of_cell_shape</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>epithelial_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id number  clump_thickness  uniformity_of_cell_size  \\\n",
       "0           0    1000025                5                        1   \n",
       "1           1    1002945                5                        4   \n",
       "2           2    1015425                3                        1   \n",
       "3           3    1016277                6                        8   \n",
       "4           4    1017023                4                        1   \n",
       "\n",
       "   uniformity_of_cell_shape  marginal_adhesion  epithelial_cell_size  \\\n",
       "0                         1                  1                     2   \n",
       "1                         4                  5                     7   \n",
       "2                         1                  1                     2   \n",
       "3                         8                  1                     3   \n",
       "4                         1                  3                     2   \n",
       "\n",
       "   bare_nuclei  bland_chromatin  normal_nucleoli  mitoses  malignant  \n",
       "0            1                3                1        1          0  \n",
       "1           10                3                2        1          0  \n",
       "2            2                3                1        1          0  \n",
       "3            4                3                7        1          0  \n",
       "4            1                3                1        1          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the id columns and separate out the dependent variable, malignant\n",
    "data = data.drop(['Unnamed: 0', 'id number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = data.pop(\"malignant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup holdout data set for test/train:\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run Grid Search on a Random Forest model to optimize:\n",
    "n_estimators = [300,400,500]\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "min_samples_split = [3,5,7]\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=1)\n",
    "estimator = GridSearchCV(rfc,\n",
    "                         dict(n_estimators=n_estimators,\n",
    "                              max_features=max_features,\n",
    "                              min_samples_split=min_samples_split\n",
    "                              ), cv=None, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'min_samples_split': [3, 5, 7], 'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [300, 400, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the training data through the optimization:\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the best parameters for the training data:\n",
    "estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: split = 3, estimators = 400\n",
    "# Store this classifier's parameters:\n",
    "best_rfc = estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.964285714286\n"
     ]
    }
   ],
   "source": [
    "# Accuracy (the number of correct predictions divided the total number of records):\n",
    "accuracy = accuracy_score(y_test, best_rfc.predict(X_test))\n",
    "print \"Accuracy: \", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.97        95\n",
      "          1       0.95      0.93      0.94        45\n",
      "\n",
      "avg / total       0.96      0.96      0.96       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision and Recall:\n",
    "print classification_report(y_test, best_rfc.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score:  0.996023391813\n"
     ]
    }
   ],
   "source": [
    "# AUC:\n",
    "roc = roc_auc_score(y_test, best_rfc.predict_proba(X_test)[:,1])\n",
    "print \"AUC Score: \", roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "scores = cross_validation.cross_val_score(best_rfc, data, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91549296,  0.97142857,  0.97142857,  0.91428571,  0.98571429,\n",
       "        0.98571429,  0.97142857,  0.98571429,  0.98550725,  0.98550725])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the range of scores across all chunks of the model:\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.967222 +/-  0.019228\n",
      "95 percent probability that if this experiment were repeated over and over the average score would be between 0.947994 and 0.986450\n"
     ]
    }
   ],
   "source": [
    "# Average these scores:\n",
    "mean_score = scores.mean()\n",
    "std_dev = scores.std()\n",
    "std_error = scores.std() / math.sqrt(scores.shape[0])\n",
    "ci =  2.262 * std_error\n",
    "lower_bound = mean_score - ci\n",
    "upper_bound = mean_score + ci\n",
    "\n",
    "print \"Score is %f +/-  %f\" % (mean_score, ci)\n",
    "print '95 percent probability that if this experiment were repeated over and over the average score would be between %f and %f' % (lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Fold Cross Validation score's average value came in nearly 3% lower than the AUC score. This is because the AUC score of 99.6% (seems nice!) was using the optimized Random Forest model on only 20% of the entire data set. This training set may or may not best represent the entire model, so the optimization drilled in to be best for this data subset. With K-Fold, the optimized model was run on 10 separate groups of the data test set with training run on the entire remaining of the data set, so the prediction capability is run on more of the entire data set and some minimal statistics provide how consistent is the model's capability. The K-Fold resulting in a (still nice!) result of 96.7% +/ 0.02."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The model above creates a Random Forest on a 20% hold out set of the data for testing. This model is run through a range of parameters to identify the optimum parameter set. This optimized set used 400 estimators and sample split of 3 for the Random Forest model generation, which was then run on the test data. The accuracy of this model was a very high 99.6% representing the number of correct predictions over the total number of records. For this data set, since there are 31% more not malignent (0) results than malignent (1), and the model is only tested on a small subset of this data, it is possible that the accuracy measure isn't representing a true performance of this model running on a more general set of data.\n",
    "\n",
    "##### The precision of the model to predict malignent (1) results is 95% meaning that it will predict this percentage of the actual '1' results. The recall on malignent (1) results is 93% meaning of the '1' results predicted, this percentage of these results will be true predictions.\n",
    "\n",
    "##### The AUC score came at a very high 99.6%, which is suggesting the model is capable of identifying all positive results and nearly no false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
